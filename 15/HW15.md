## HW15

#### Q1

(1) 根据最小二乘法，有 $\hat \beta_1 = \dfrac{\sum_{i=1}^{n}(x_i-\bar x)(y_i-\bar y)}{\sum_{i=1}^n (x_i-\bar x)^2 }$，$\hat \beta_0=\bar y - \hat \beta_1 \bar x$。于是 $\bar y = \hat \beta_0 + \hat \beta_1x$，即最小二乘法拟合的直线经过点 $(\bar x, \bar y)$。

(2) $Cov(\hat \beta_0, \hat \beta_1)=Cov(\bar y - \hat \beta_1 \bar x, \hat \beta_1) = -\bar x Cov(\hat\beta_1, \hat\beta_1)=-\bar x Var(\hat \beta _1) = -\dfrac{\bar x \sigma^2}{S_{xx}}$

当 $\bar x = 0$ 时，$Cov(\hat \beta_0, \hat \beta_1)=0$，此时 $\hat \beta_0, \hat \beta_1$ 不相关。

(3) $Var(\hat\beta_1)=\dfrac{\sigma^2}{S_{xx}}=\dfrac{\sigma^2}{\sum_{i=1}^n(x_i-\bar x)^2}$，要最小化 $Var(\hat \beta_1)$，需要最大化 $\sum_{i=1}^n(x_i-\bar x)^2$，为此，当 $n$ 为偶数时，取 $x_i$ 一半为 $-1$，一半为 $1$ 即可；若 $n$ 为奇数时，取 $-1$ 和 $1$ 的数目分别为 $\dfrac{n-1}2$ 和 $\dfrac{n+1}2$，或 $\dfrac{n+1}2$ 和 $\dfrac{n-1}2$。

(4) 若 $\beta_0=0$，则定义损失函数 $s(\beta_1)=\sum_{i=1}^n(y_i-\beta_1x_i)^2$。求导，得 $\dfrac {\mathrm{d}s} {\mathrm{d}\beta_1}\bigg|_{\beta_1=\hat\beta_1}=\sum_{i=1}^{n}(-2x_i(y_i-\hat \beta_1 x_i))=0$，于是 $\hat \beta_1=\dfrac{\sum_{i=1}^n x_iy_i}{\sum_{i=1}^n x_i^2}$

#### Q2

(1) 似然函数 $L(\sigma^2)=\prod_{i=1}^n\dfrac 1 {\sqrt{2\pi}\sigma}e^{-\frac{\epsilon_i^2}{2\sigma^2}}$，其中 $\epsilon_i=y_i-(\hat \beta_0+\hat \beta_1x_i)$

所以 $\log L(\sigma^2)=\sum_{i=1}^n \left[-\log (\sqrt{2\pi}\sigma)-\dfrac{\epsilon_i^2}{2\sigma^2} \right]=-n\log (\sqrt{2\pi}\sigma)-\dfrac{SSE}{2\sigma^2}$，令 $\dfrac{\mathrm{d}\log L}{\mathrm{d}\sigma}=-\dfrac n {\sigma}+\dfrac{SSE}{\sigma^3}=0$，解得 $ (\sigma^2)^* = \dfrac{SSE} n$。

(2) 证明：

$$
\begin{align}
SSE&=\sum_{i=1}^n(y_i-(\hat \beta_0+\hat\beta_1x_i))^2\\
&=\sum_{i=1}^n((y_i-\bar y)-(\hat \beta_0+\hat\beta_1x_i-\bar y))^2\\
&=\sum_{i=1}^n((y_i-\bar y)-\hat \beta_1(x_i-\bar x))^2\\
&=\sum_{i=1}^n(y_i-\bar y)^2+\hat \beta_1^2\sum_{i=1}^n(x_i-\bar x)^2-2\hat \beta_1\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)\\
&=\sum_{i=1}^n(y_i-\bar y)^2+\hat \beta_1^2\sum_{i=1}^n(x_i-\bar x)^2-2\hat \beta_1(\hat \beta_1\sum_{i=1}^n(x_i-\bar x)^2)\\
&=\sum_{i=1}^n(y_i-\bar y)^2-\hat \beta_1^2\sum_{i=1}^n(x_i-\bar x)^2
\end{align}
$$

其中，

$$
\begin{align}
\sum_{i=1}^n(y_i-\bar y)^2&=\sum_{i=1}^n(\beta_1(x_i-\bar x)+\epsilon_i)^2\\
&=\beta_1^2\sum_{i=1}^n(x_i-\bar x)^2+2\beta_1\sum_{i=1}^n(x_i-\bar x)\epsilon_i+\sum_{i=1}^n\epsilon_i^2\\
&=\beta_1^2\sum_{i=1}^n(x_i-\bar x)^2+\sum_{i=1}^n\epsilon_i^2\\
E(\sum_{i=1}^n(y_i-\bar y)^2)&=\beta_1^2\sum_{i=1}^n(x_i-\bar x)^2+\sum_{i=1}^n\epsilon_i^2\\
\end{align}
$$

且

$$
E(\hat \beta_1^2)=Var(\hat \beta_1)+E^2(\hat \beta_1)=\dfrac{\sigma^2}{\sum_{i=1}^n(x_i-\bar x)^2}+\beta_1^2\\
E(\hat \beta_1^2\sum_{i=1}^n(x_i-\bar x)^2)=E(\hat \beta_1^2)\sum_{i=1}^n(x_i-\bar x)^2=\sigma^2+\beta_1^2\sum_{i=1}^n(x_i-\bar x)^2
$$

所以，

$$
\begin{align}
E(SSE)&=E(\sum_{i=1}^n(y_i-\bar y)^2-\hat \beta_1^2\sum_{i=1}^n(x_i-\bar x)^2)\\
&=E(\sum_{i=1}^n(y_i-\bar y)^2)-E(\hat \beta_1^2\sum_{i=1}^n(x_i-\bar x)^2)\\
&=\beta_1^2\sum_{i=1}^n(x_i-\bar x)^2+\sum_{i=1}^n\epsilon_i^2-(\sigma^2+\beta_1^2\sum_{i=1}^n(x_i-\bar x)^2)\\
&=\sum_{i=1}^n\epsilon_i^2-\sigma^2\\
&=(n-1)\sigma^2-\sigma^2\\
&=(n-2)\sigma^2
\end{align}
$$

故 $E\left(\dfrac{SSE}{n-2}\right)=\sigma^2$，即 $\dfrac{SSE}{n-2}$ 是 $\sigma^2$ 的无偏估计。

(3) $\sigma^2$ 的一个无偏估计为 $\dfrac{\sum_{i=1}^n(y_i-\hat \beta_1 x_i)^2}{n-1}$。由于 $\dfrac{y_0-\hat y_0}{\sigma \sqrt{1+\dfrac{x_0^2}{\sum_{i=1}^nx_i^2}}}\sim N(0,1)$，$\dfrac{(n-1)\hat \sigma^2}{\sigma^2}\sim \chi^2(n-1)$，且两者独立，所以 $\dfrac{y_0-\hat y_0}{\hat \sigma \sqrt{1+\dfrac{x_0^2}{\sum_{i=1}^nx_i^2}}}\sim t(n-1)$，$y_0$ 的 $(1-\alpha)$-置信区间估计为 $\left[\hat y_0-t_{\frac{\alpha}2}(n-1)\hat \sigma \sqrt{1+\dfrac{x_0^2}{\sum_{i=1}^nx_i^2}},\hat y_0+t_{\frac{\alpha}2}(n-1)\hat \sigma \sqrt{1+\dfrac{x_0^2}{\sum_{i=1}^nx_i^2}} \right]$。